{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ffd84e",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30de8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "import inflection\n",
    "import requests\n",
    "import pickle\n",
    "from IPython.display import Image\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c690c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ml_error(model_name, y_test, yhat):\n",
    "#    mae = (np.sum(np.abs(np.expm1(y_test) - np.expm1(yhat))))/len(np.expm1(yhat))\n",
    "#    mape = np.sum(np.abs(np.expm1(y_test) - np.expm1(yhat))/np.expm1(yhat))/len(yhat)\n",
    "#    rmse = np.sqrt((np.sum((np.expm1(y_test) - np.expm1(yhat))**2))/len(np.expm1(yhat)))\n",
    "#    #mae = mean_absolute_error(np.expm1(y_test),np.expm1(yhat))\n",
    "#    #mape = mean_absolute_percentage_error(np.expm1(y_test),np.expm1(yhat))\n",
    "#    #rmse = mean_squared_error(np.expm1(y_test),np.expm1(yhat))  \n",
    "#    \n",
    "#    return {'Model name': model_name,\n",
    "#            'MAE': mae,\n",
    "#            'MAPE': mape,\n",
    "#            'RMSE': rmse}\n",
    "#\n",
    "#def cross_validation(x_training, kfold, model_name, model):\n",
    "#    l_mae = []\n",
    "#    l_mape = []\n",
    "#    l_rmse = []\n",
    "#\n",
    "#    for k in range(kfold,0,-1):\n",
    "#        start_validation = x_training['date'].max() - datetime.timedelta(days=6*7*k)\n",
    "#        end_validation = x_training['date'].max() - datetime.timedelta(days=6*7*(k-1))\n",
    "#        \n",
    "#        training = x_training[x_training['date'] < start_validation]\n",
    "#        validation = x_training[(x_training['date'] >= start_validation) & (x_training['date'] <= end_validation)]\n",
    "#        \n",
    "#        xtraining = training.drop(['date','sales'], axis=1)\n",
    "#        ytraining = training['sales']\n",
    "#        \n",
    "#        xvalidation = validation.drop(['date','sales'], axis=1)\n",
    "#        yvalidation = validation['sales']\n",
    "#        \n",
    "#        m = model.fit(xtraining, ytraining)\n",
    "#        yhat = m.predict(xvalidation)\n",
    "#        \n",
    "#        m_result = ml_error(model_name, yvalidation, yhat)\n",
    "#        \n",
    "#        mae = (np.sum(np.abs(np.expm1(yvalidation) - np.expm1(yhat))))/len(np.expm1(yhat))\n",
    "#        mape = np.sum(np.abs(np.expm1(yvalidation) - np.expm1(yhat))/np.expm1(yhat))/len(yhat)\n",
    "#        rmse = np.sqrt((np.sum((np.expm1(yvalidation) - np.expm1(yhat))**2))/len(np.expm1(yhat)))\n",
    "#        #mae = mean_absolute_error(np.expm1(y_test_temp),np.expm1(yhat))\n",
    "#        #mape = mean_absolute_percentage_error(np.expm1(y_test_temp),np.expm1(yhat))\n",
    "#        #rmse = mean_squared_error(np.expm1(y_test_temp),np.expm1(yhat))  \n",
    "#        l_mae.append(mae)\n",
    "#        l_mape.append(mape)\n",
    "#        l_rmse.append(rmse)\n",
    "#        \n",
    "#        \n",
    "#    return {'Model Name':model_name,\n",
    "#            'MAE CV':np.round(np.mean(l_mae),2).astype(str) + ' +/- ' + np.round(np.std(l_mae),2).astype(str),\n",
    "#            'MAPE CV':np.round(np.mean(l_mape),2).astype(str) + ' +/- ' + np.round(np.std(l_mape),2).astype(str),\n",
    "#            'RMSE CV':np.round(np.mean(l_rmse),2).astype(str) + ' +/- ' + np.round(np.std(l_rmse),2).astype(str)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aeb18e",
   "metadata": {},
   "source": [
    "# 11. Deploy do modelo para produção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c456cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(tuned_model_xgb, open('model/model_rossmann.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f08b2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f89ed0e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import inflection\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import math\n",
    "#import datetime\n",
    "#\n",
    "#class Rossmann(object):\n",
    "#    def __init__(self):\n",
    "#        self.home_patch='C:/Users/carli/Documents/#Python/comunidade_ds/repos/ds_em_producao/'\n",
    "#        self.competition_distance_scaler = pickle.load(open(self.home_patch+'parameter/competition_distance_scaler.pkl', 'rb'))\n",
    "#        self.competition_time_month_scaler = pickle.load(open(self.home_patch+'parameter/competition_time_month_scaler.pkl', 'rb'))\n",
    "#        self.promo_time_week_scaler = pickle.load(open(self.home_patch+'parameter/promo_time_week_scaler.pkl', 'rb'))\n",
    "#        self.year_scaler = pickle.load(open(self.home_patch+'parameter/year_scaler.pkl', 'rb'))\n",
    "#        self.store_type_scaler = pickle.load(open(self.home_patch+'parameter/store_type_scaler.pkl', 'rb'))\n",
    "#    \n",
    "#    def data_cleaning(self, df2):\n",
    "#        snakecase = lambda x: inflection.underscore(x)\n",
    "#        df2.columns = list(map(snakecase, df2.columns))\n",
    "#        #df2.drop(['sales','customers'], axis=1) #???<<<\n",
    "#        df2['date'] = pd.to_datetime(df2['date'])\n",
    "#        df2['competition_distance'] = df2['competition_distance'].apply(lambda x: 200000.0 if math.isnan(x) else x)\n",
    "#        df2['competition_open_since_month'] = df2.apply(lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) else x['competition_open_since_month'], axis=1)\n",
    "#        df2['competition_open_since_year'] = df2.apply(lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) else x['competition_open_since_year'], axis=1)\n",
    "#        df2['promo2_since_week'] = df2.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) else x['promo2_since_week'], axis=1)\n",
    "#        df2['promo2_since_year'] = df2.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) else x['promo2_since_year'], axis=1)\n",
    "#        calendar = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "#        df2['promo_interval'].fillna(0, inplace=True)\n",
    "#        df2['calendar'] = df2['date'].dt.month.map(calendar)\n",
    "#        df2['is_promo'] = df2[['promo_interval','calendar']].apply(lambda x: 0 if x['promo_interval'] == 0 else 1 if x['calendar'] in x['promo_interval'].split(',') else 0, axis=1)        \n",
    "#        df2['competition_open_since_month'] = df2['competition_open_since_month'].astype(int)\n",
    "#        df2['competition_open_since_year'] = df2['competition_open_since_year'].astype(int)\n",
    "#        df2['promo2_since_week'] = df2['promo2_since_week'].astype(int)\n",
    "#        df2['promo2_since_year'] = df2['promo2_since_year'].astype(int)        \n",
    "#        return df2\n",
    "#    \n",
    "#    def feature_engineering(self,df3):\n",
    "#        df3['year'] = df3['date'].dt.year\n",
    "#        df3['month'] = df3['date'].dt.month\n",
    "#        df3['day'] = df3['date'].dt.day\n",
    "#        df3['week_of_year'] = df3['date'].dt.isocalendar().week\n",
    "#        df3['year_week'] = df3['date'].dt.strftime('%Y-%W')\n",
    "#        df3['competition_since'] = df3.apply(lambda x: datetime.datetime(year=x['competition_open_since_year'], month=x['competition_open_since_month'], day=1), axis=1)\n",
    "#        df3['competition_time_month'] = ((df3['date'] - df3['competition_since'])/30).apply(lambda x: x.days).astype(int)\n",
    "#        df3['promo_since'] = df3['promo2_since_year'].astype(str) + '-' + df3['promo2_since_week'].astype(str)\n",
    "#        df3['promo_since'] = df3['promo_since'].apply(lambda x: datetime.datetime.strptime(x+'-1','%Y-%W-%w') - datetime.timedelta(days=7))\n",
    "#        df3['promo_time_week'] = ((df3['date'] - df3['promo_since'])/7).apply(lambda x: x.days).astype(int)\n",
    "#        df3['assortment'] = df3['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended')\n",
    "#        df3['state_holiday'] = df3['state_holiday'].apply(lambda x: 'public holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day')\n",
    "#        df3 = df3[df3['open'] != 0]\n",
    "#        df3.drop(['open','promo_interval','calendar'], axis=1, inplace=True)\n",
    "#        return df3\n",
    "#    \n",
    "#    def data_preparation(self,df6):\n",
    "#        df6['competition_distance'] = self.competition_distance_scaler.transform(df6[['competition_distance']].values)\n",
    "#        df6['competition_time_month'] = self.competition_time_month_scaler.transform(df6[['competition_time_month']].values)\n",
    "#        df6['promo_time_week'] = self.promo_time_week_scaler.transform(df6[['promo_time_week']].values)\n",
    "#        df6['year'] = self.year_scaler.transform(df6[['year']].values)\n",
    "#        df6 = pd.get_dummies(df6,prefix=['state_holiday'], columns=['state_holiday'])\n",
    "#        df6['store_type'] = self.store_type_scaler.transform(df6['store_type'])\n",
    "#        assortment_dict = {'basic':1, 'extra':2, 'extended':3}\n",
    "#        df6['assortment'] = df6['assortment'].map(assortment_dict)\n",
    "#        df6['day_of_week_sin'] = df6['day_of_week'].apply(lambda x: np.sin(x*(2.*np.pi/7)))\n",
    "#        df6['day_of_week_cos'] = df6['day_of_week'].apply(lambda x: np.cos(x*(2.*np.pi/7)))\n",
    "#        df6['month_sin'] = df6['month'].apply(lambda x: np.sin(x*(2.*np.pi/12)))\n",
    "#        df6['month_cos'] = df6['month'].apply(lambda x: np.cos(x*(2.*np.pi/12)))\n",
    "#        df6['day_sin'] = df6['day'].apply(lambda x: np.sin(x*(2.*np.pi/30)))\n",
    "#        df6['day_cos'] = df6['day'].apply(lambda x: np.cos(x*(2.*np.pi/30)))\n",
    "#        df6['week_of_year_sin'] = df6['week_of_year'].apply(lambda x: np.sin(x*(2.*np.pi/52)))\n",
    "#        df6['week_of_year_cos'] = df6['week_of_year'].apply(lambda x: np.cos(x*(2.*np.pi/52)))\n",
    "#        \n",
    "#        cols_selected = ['store','promo','store_type','assortment','competition_distance',\n",
    "#                                'competition_open_since_month','competition_open_since_year',\n",
    "#                                'promo2','promo2_since_week','promo2_since_year',\n",
    "#                                'competition_time_month','promo_time_week','day_of_week_sin',\n",
    "#                                'day_of_week_cos','month_sin','month_cos','day_sin','day_cos',\n",
    "#                                'week_of_year_cos','week_of_year_sin']\n",
    "#        \n",
    "#        return df6[cols_selected]\n",
    "#    \n",
    "#    def get_prediction(self, model, original_data, test_data):\n",
    "#        #Prediction\n",
    "#        pred = model.predict(test_data)\n",
    "#        \n",
    "#        #join pred into original data\n",
    "#        original_data['prediction'] = np.expm1(pred)\n",
    "#        return original_data.to_json(orient='records', date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6b72b1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81a22497",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import pandas as pd\n",
    "#from flask import Flask, request, Response\n",
    "#from rossmann.Rossmann import Rossmann\n",
    "#\n",
    "##loading model\n",
    "#model = pickle.load(open(r'C:\\Users\\carli\\Documents\\#Python\\comunidade_ds\\repos\\ds_em_producao\\model\\model_rossmann.pkl', 'rb'))\n",
    "#\n",
    "#\n",
    "#app = Flask(__name__)\n",
    "#@app.route('/rossmann/predict', methods=['POST'])\n",
    "#def rossmann_predict():\n",
    "#    test_json = request.get_json()\n",
    "#    if test_json: #Se houver dados\n",
    "#        \n",
    "#        if isinstance(test_json, dict): #Linha única\n",
    "#            test_raw = pd.DataFrame(test_json, index=[0])\n",
    "#            \n",
    "#        else: #Múltiplas linhas\n",
    "#            test_raw = pd.DataFrame(test_json, columns=test_json[0].keys())\n",
    "#    \n",
    "#        #Instantiate Rossmann Class\n",
    "#        pipeline = Rossmann()\n",
    "#\n",
    "#        #data cleaning\n",
    "#        df1 = pipeline.data_cleaning(test_raw)\n",
    "#\n",
    "#        #feature engineering\n",
    "#        df2 = pipeline.feature_engineering(df1)\n",
    "#\n",
    "#        #data preparation\n",
    "#        df3 = pipeline.data_preparation(df2)\n",
    "#\n",
    "#        #predictions\n",
    "#        df_response = pipeline.get_prediction(model, test_raw, df3)\n",
    "#\n",
    "#        return df_response\n",
    "#\n",
    "#    else: #Se não houver dados\n",
    "#        return Response('{}', status=200, minetype='application/json')\n",
    "#\n",
    "#if __name__ == '__main__':\n",
    "#    app.run('192.168.3.6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e06c0",
   "metadata": {},
   "source": [
    "### API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb19e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv('data/train.csv', low_memory=False)\n",
    "df_store = pd.read_csv('data/store.csv', low_memory=False)\n",
    "df1 = pd.merge(df_sales, df_store, how='left', on='Store')\n",
    "df11 = pd.read_csv('./data/test.csv')\n",
    "store_list = [7, 15, 12, 122]\n",
    "\n",
    "#Merge test.csv + store.csv\n",
    "df_test = pd.merge(df11, df_store, how='left', on='Store')\n",
    "\n",
    "#Choose store for prediction\n",
    "df_test = df_test[df_test['Store'].isin(store_list)]\n",
    "\n",
    "#Remove closed store days\n",
    "df_test = df_test[df_test['Open'] != 0]\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "df_test = df_test.drop('Id', axis=1)\n",
    "\n",
    "#Convert Dataframe to json\n",
    "data = json.dumps(df_test.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac113cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code 200\n"
     ]
    }
   ],
   "source": [
    "#API Call\n",
    "#url = '0.0.0.0:5000/rossmann/predict'\n",
    "url = 'HTTP://192.168.3.6:5000/rossmann/predict'\n",
    "#url = 'https://rossmann-predm.herokuapp.com/rossmann/predict' #Pra onde vou enviar esse pedido?\n",
    "header = {'Content-type':'application/json'} #Indica que tipo de dado a API esta recebendo\n",
    "data = data #Dado\n",
    "\n",
    "r = requests.post(url, data=data, headers=header) #Método .post, onde envio um dado para fazer um pedido\n",
    "print('Status code {}'.format(r.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f95febf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store 7 will sell 377,200.67 in next 6 weeks.\n",
      "Store 12 will sell 295,849.37 in next 6 weeks.\n",
      "Store 15 will sell 276,622.29 in next 6 weeks.\n",
      "Store 122 will sell 344,020.52 in next 6 weeks.\n"
     ]
    }
   ],
   "source": [
    "d1 = pd.DataFrame(r.json(), columns=r.json()[0].keys())\n",
    "d2 = d1[['store','prediction']].groupby('store').sum().reset_index()\n",
    "for i in range(len(d2)):\n",
    "    print('Store {} will sell {:,.2f} in next 6 weeks.'.format(d2.loc[i,'store'],d2.loc[i,'prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5dc766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
